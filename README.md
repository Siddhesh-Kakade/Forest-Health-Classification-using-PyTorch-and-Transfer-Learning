# Forest-Health-Classification-using-PyTorch-and-Transfer-Learning
cv-pytorch-forest-health-transfer learning

This project uses a PyTorch-based computer vision model to classify the health of trees from aerial images. The model is trained to identify different levels of forest damage based on XML annotations, achieving a final, balanced accuracy of 86.05%.

The classification task involves four distinct categories:

H (Healthy)

LD (Light Damage)

HD (Heavy Damage)

other (Other non-tree objects)

This notebook (main.ipynb) documents the entire workflow, from raw data processing to advanced model tuning.

(This image will be generated by the notebook)

Key Features

This project is a complete case study in iterative model tuning, demonstrating how to solve common deep learning challenges:

Model: ResNet50 (using Transfer Learning).

Class Imbalance: Solved using a WeightedRandomSampler and a Weighted CrossEntropyLoss to force the model to pay attention to rare classes.

Overfitting: Controlled using Dropout layers and Weight Decay (AdamW optimizer).

Fine-Tuning: Uses Partial Fine-Tuning (unfreezing only the top layers) to adapt the pre-trained model to the specific task.

Optimization: Implements Early Stopping to find the best-performing model epoch and save it for evaluation.

Methodology

The final model was the result of a multi-stage tuning process to overcome a severe class imbalance problem.

1. Data Preprocessing

Input: .JPG images and .xml annotation files (PASCAL VOC format).

Process: A script parses the XML files to find the bounding box (<bndbox>) and the damage label (<damage>) for each tree.

Output: Each tree is cropped from the main image, resized to 224x224, and saved into a new directory structure (processed_data/) organized by its class (e.g., LD, HD), ready for ImageFolder.

2. Initial Model & Diagnosis

A simple ResNet18 model was first trained, revealing a classic class imbalance problem. The model achieved high accuracy (~78%) by "lazily" predicting the most common class (LD) for almost every image.

3. Advanced Tuning & Optimization

To solve this, several techniques were layered on, resulting in the final ResNet50-based model:

Weighted Sampling: A WeightedRandomSampler was used in the DataLoader to oversample rare classes like H and HD during training.

Weighted Loss: The CrossEntropyLoss function itself was given weights to heavily penalize misclassifications of the rare classes.

Regularization: To control the overfitting from the more powerful ResNet50, Dropout and Weight Decay were added.

Partial Fine-Tuning: Only the final blocks (layer3, layer4, and fc) of the ResNet50 were unfrozen for training. This retains the powerful, general features of the early layers while teaching the later layers to specialize in forest health.

Final Results

The final, tuned model is highly balanced and effective, demonstrating a strong ability to distinguish between all classes.

Final Test Accuracy: 86.05%

Confusion Matrix

The heatmap clearly shows the model's performance, with strong predictions along the diagonal. The most common confusion (e.g., H vs. LD) is minimal and aligns with real-world visual ambiguity.

(This image will be generated by the notebook)

Training & Validation History

The plots for accuracy and loss show a well-fit model, with the validation accuracy (red) tracking the training accuracy (blue) closely before the Early Stopping point.

(This image will be generated by the notebook)

How to Run

Clone the repository:

git clone [https://Siddhesh-Kakade/Forest-Health-Classification-using-PyTorch-and-Transfer-Learning.git](https://Siddhesh-Kakade/Forest-Health-Classification-using-PyTorch-and-Transfer-Learning.git)


Prepare the Data:
Download the data from [drive](https://drive.google.com/file/d/1t34anYxAr0jDIJJSQway05X2SCe0tZ8t/view?usp=sharing). 
This notebook expects your raw data to be in a main Forest2/ folder.

Create the following subdirectories: Forest2/train_images/, Forest2/train_annotations/, Forest2/test_images/, Forest2/test_annotations/.

Place your .JPG and .xml files into the corresponding folders.

Environment:

Upload this notebook and your Forest2 folder to Google Drive or the Colab environment.

Open the notebook in Google Colab.

Ensure you are using a GPU runtime (Runtime -> Change runtime type -> T4 GPU).

Run All Cells:

The first cell will process all your raw data and create the processed_data/ folders.

The subsequent cells will load this processed data, train the model, and generate the final evaluations and visualizations.
